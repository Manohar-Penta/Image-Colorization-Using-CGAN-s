{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image-Colorization-with-CGANs.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhdnxWB2WFBEN36MmMOX2T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manohar-Penta/Image-Colorization-Using-CGAN-s/blob/main/Image_Colorization_with_CGANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHfWfblJrgcn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing required Software and Modules to Colab"
      ],
      "metadata": {
        "id": "zSQvcZmtolu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U fastai\n",
        "!pip install -U albumentations"
      ],
      "metadata": {
        "id": "F1ZaBf83orBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import optim\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from fastai.data.external import untar_data, URLs\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "import matplotlib.pyplot as plt\n",
        "from fastai.vision.learner import create_body\n",
        "from torchvision.models.resnet import resnet18\n",
        "from fastai.vision.models.unet import DynamicUnet"
      ],
      "metadata": {
        "id": "9DvZlTsgujoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Images from Coco Image dataset"
      ],
      "metadata": {
        "id": "8TKiGRM3wEaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading images from COCO dataset and storing the paths of the 10000 images for training and testing purposes."
      ],
      "metadata": {
        "id": "j3MTCFphjg1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coco_path = untar_data(URLs.COCO_SAMPLE)\n",
        "coco_path = str(coco_path) + \"/train_sample\"\n",
        "paths = glob.glob(coco_path + \"/*.jpg\")\n",
        "print(coco_path)\n",
        "np.random.seed(123)\n",
        "paths_subset = np.random.choice(paths, 10_000, replace=False)\n",
        "rand_idxs = np.random.permutation(10_000)\n",
        "train_idxs = rand_idxs[:8000]\n",
        "val_idxs = rand_idxs[8000:]\n",
        "train_paths = paths_subset[train_idxs]\n",
        "val_paths = paths_subset[val_idxs]\n",
        "print(len(train_paths), len(val_paths))"
      ],
      "metadata": {
        "id": "oyjnzH2ir5He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scvy7B9s_zzy"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
        "for ax, img_path in zip(axes.flatten(), train_paths):\n",
        "    ax.imshow(Image.open(img_path))\n",
        "    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "r-jySgcxo5Si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I'm resizing the images and flipping horizontally (flipping only if it is training set) and then I read an RGB image, convert it to Lab color space and separate the first (grayscale) channel and the color channels as my inputs and targets for the models respectively. Then I'm making the data loaders."
      ],
      "metadata": {
        "id": "e4X9ImaJj6lA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhD8_eqt_zzy"
      },
      "outputs": [],
      "source": [
        "SIZE = 256\n",
        "class ColorizationDataset(Dataset):\n",
        "    def __init__(self, paths, split='train'):\n",
        "        if split == 'train': # for training model\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(10)\n",
        "            ])\n",
        "        elif split == 'val': # for test cases\n",
        "            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n",
        "        \n",
        "        self.split = split\n",
        "        self.size = SIZE\n",
        "        self.paths = paths\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        img = self.transforms(img)\n",
        "        img = np.array(img)\n",
        "        img_lab = rgb2lab(img).astype(\"float32\")\n",
        "        img_lab = transforms.ToTensor()(img_lab)\n",
        "        L = img_lab[[0], ...] / 50. - 1. # feature Scaling\n",
        "        ab = img_lab[[1, 2], ...] / 110. # feature Scaling\n",
        "        \n",
        "        return {'L': L, 'ab': ab}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "def make_dataloaders(batch_size=16, n_workers=4, pin_memory=True, **kwargs):\n",
        "    dataset = ColorizationDataset(**kwargs)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n",
        "                            pin_memory=pin_memory)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REbjC_bc_zzz"
      },
      "outputs": [],
      "source": [
        "train_dl = make_dataloaders(paths=train_paths, split='train')\n",
        "val_dl = make_dataloaders(paths=val_paths, split='val')\n",
        "\n",
        "data = next(iter(train_dl))\n",
        "Ls, abs_ = data['L'], data['ab']\n",
        "print(Ls.shape, abs_.shape)\n",
        "print(len(train_dl), len(val_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The U-Net Generator"
      ],
      "metadata": {
        "id": "tZwVxiw1pRT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements a U-Net to be used as the generator of our GAN."
      ],
      "metadata": {
        "id": "L8zRa4r0kVJe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RWEqk7h_zz0"
      },
      "outputs": [],
      "source": [
        "class UnetBlock(nn.Module):\n",
        "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
        "                 innermost=False, outermost=False):\n",
        "        super().__init__()\n",
        "        self.outermost = outermost\n",
        "        if input_c is None: input_c = nf\n",
        "        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n",
        "                             stride=2, padding=1, bias=False)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = nn.BatchNorm2d(ni)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = nn.BatchNorm2d(nf)\n",
        "        \n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1, bias=False)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1, bias=False)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            if dropout: up += [nn.Dropout(0.5)]\n",
        "            model = down + [submodule] + up\n",
        "        self.model = nn.Sequential(*model)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], 1)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
        "        super().__init__()\n",
        "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
        "        for _ in range(n_down - 5):\n",
        "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
        "        out_filters = num_filters * 8\n",
        "        for _ in range(3):\n",
        "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
        "            out_filters //= 2\n",
        "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The PatchGAN Discriminator"
      ],
      "metadata": {
        "id": "5v8Dj19-pcex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture of our discriminator is rather straight forward. This code implements a model by stacking blocks of Conv-BatchNorm-LeackyReLU to decide whether the input image is fake or real. Notice that the first and last blocks do not use normalization and the last block has no activation function (it is embedded in the loss function we will use)."
      ],
      "metadata": {
        "id": "01t7WMWdk4Up"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBJpDwQF_zz1"
      },
      "outputs": [],
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
        "        super().__init__()\n",
        "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
        "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n",
        "                          for i in range(n_down)] \n",
        "                                                 \n",
        "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] \n",
        "                                                                                             \n",
        "        self.model = nn.Sequential(*model)                                                   \n",
        "        \n",
        "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): \n",
        "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          \n",
        "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
        "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qefeTLB_zz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf7189a6-400e-4875-d605-9dd288a7141d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1, 30, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "discriminator = PatchDiscriminator(3)\n",
        "dummy_ip = torch.randn(16, 3, 256, 256) # batch_size, channels, size, size\n",
        "out = discriminator(dummy_ip)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN Loss"
      ],
      "metadata": {
        "id": "luY2MaJTp4Yf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZi_qCK5_zz3"
      },
      "outputs": [],
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
        "        if gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "    \n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        if target_is_real:\n",
        "            labels = self.real_label\n",
        "        else:\n",
        "            labels = self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "    \n",
        "    def __call__(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        loss = self.loss(preds, labels)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Initializing Function"
      ],
      "metadata": {
        "id": "ahgFN4NBqAZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to initialize the weights of our model with a mean of 0.0 and standard deviation of 0.02."
      ],
      "metadata": {
        "id": "Qm0v2-BFlSGW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ80e2bU_zz4"
      },
      "outputs": [],
      "source": [
        "def init_weights(net, init='norm', gain=0.02):\n",
        "    \n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
        "            if init == 'norm':\n",
        "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
        "            elif init == 'xavier':\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
        "            elif init == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            \n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif 'BatchNorm2d' in classname:\n",
        "            nn.init.normal_(m.weight.data, 1., gain)\n",
        "            nn.init.constant_(m.bias.data, 0.)\n",
        "            \n",
        "    net.apply(init_func)\n",
        "    print(f\"model is initialized with {init} initialization\")\n",
        "    return net\n",
        "\n",
        "def init_model(model, device):\n",
        "    model = model.to(device)\n",
        "    model = init_weights(model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Model"
      ],
      "metadata": {
        "id": "0D4kJDQJqIGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class brings together all the previous parts and implements a few methods to take care of training our complete model.In the init we define our generator and discriminator using the previous functions and classes we defined and we also initialize them with init_model function. The whole work is being done in optimize method of this class. First and only once per iteration (batch of training set) we call the module's forward method and store the outputs in fake_color variable of the class.\n",
        "\n",
        "Then, we first train the discriminator by using backward_D method in which we feed the fake images produced by generator to the discriminator (make sure to detach them from the generator's graph so that they act as a constant to the discriminator, like normal images) and label them as fake. Then we feed a batch of real images from training set to the discriminator and label them as real. We add up the two losses for fake and real and take the average and then call the backward on the final loss. Now, we can train the generator. In backward_G method we feed the discriminator the fake image and try to fool it by assigning real labels to them and calculating the adversarial loss. Then we use L1 loss as well and compute the distance between the predicted two channels and the target two channels and multiply this loss by a coefficient (which is 100 in our case) to balance the two losses and then add this loss to the adversarial loss. Then we call the backward method of the loss."
      ],
      "metadata": {
        "id": "z4pN6KrtlZa2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpHJP-h9_zz5"
      },
      "outputs": [],
      "source": [
        "class MainModel(nn.Module):\n",
        "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, \n",
        "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.lambda_L1 = lambda_L1\n",
        "        \n",
        "        if net_G is None:\n",
        "            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n",
        "        else:\n",
        "            self.net_G = net_G.to(self.device)\n",
        "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
        "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
        "        self.L1criterion = nn.L1Loss()\n",
        "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "    \n",
        "    def set_requires_grad(self, model, requires_grad=True):\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = requires_grad\n",
        "        \n",
        "    def setup_input(self, data):\n",
        "        self.L = data['L'].to(self.device)\n",
        "        self.ab = data['ab'].to(self.device)\n",
        "        \n",
        "    def forward(self):\n",
        "        self.fake_color = self.net_G(self.L)\n",
        "    \n",
        "    def backward_D(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image.detach())\n",
        "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
        "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
        "        real_preds = self.net_D(real_image)\n",
        "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
        "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
        "        self.loss_D.backward()\n",
        "    \n",
        "    def backward_G(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image)\n",
        "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
        "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
        "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
        "        self.loss_G.backward()\n",
        "    \n",
        "    def optimize(self):\n",
        "        self.forward()\n",
        "        self.net_D.train()\n",
        "        self.set_requires_grad(self.net_D, True)\n",
        "        self.opt_D.zero_grad()\n",
        "        self.backward_D()\n",
        "        self.opt_D.step()\n",
        "        \n",
        "        self.net_G.train()\n",
        "        self.set_requires_grad(self.net_D, False)\n",
        "        self.opt_G.zero_grad()\n",
        "        self.backward_G()\n",
        "        self.opt_G.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some necessary functions"
      ],
      "metadata": {
        "id": "opgOGPy6qRFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are just some necessary functions to log the losses of our network and also visualize the results during training."
      ],
      "metadata": {
        "id": "wK1huRbzl0CP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4epHCNh_zz5"
      },
      "outputs": [],
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "        self.count, self.avg, self.sum = [0.] * 3\n",
        "    \n",
        "    def update(self, val, count=1):\n",
        "        self.count += count\n",
        "        self.sum += count * val\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def create_loss_meters():\n",
        "    loss_D_fake = AverageMeter()\n",
        "    loss_D_real = AverageMeter()\n",
        "    loss_D = AverageMeter()\n",
        "    loss_G_GAN = AverageMeter()\n",
        "    loss_G_L1 = AverageMeter()\n",
        "    loss_G = AverageMeter()\n",
        "    \n",
        "    return {'loss_D_fake': loss_D_fake,\n",
        "            'loss_D_real': loss_D_real,\n",
        "            'loss_D': loss_D,\n",
        "            'loss_G_GAN': loss_G_GAN,\n",
        "            'loss_G_L1': loss_G_L1,\n",
        "            'loss_G': loss_G}\n",
        "\n",
        "def update_losses(model, loss_meter_dict, count):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        loss = getattr(model, loss_name)\n",
        "        loss_meter.update(loss.item(), count=count)\n",
        "\n",
        "def lab_to_rgb(L, ab):\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "    rgb_imgs = []\n",
        "    for img in Lab:\n",
        "        img_rgb = lab2rgb(img)\n",
        "        rgb_imgs.append(img_rgb)\n",
        "    return np.stack(rgb_imgs, axis=0)\n",
        "    \n",
        "def visualize(model, data, save=True):\n",
        "    model.net_G.eval()\n",
        "    with torch.no_grad():\n",
        "        model.setup_input(data)\n",
        "        model.forward()\n",
        "    model.net_G.train()\n",
        "    fake_color = model.fake_color.detach()\n",
        "    real_color = model.ab\n",
        "    L = model.L\n",
        "    fake_imgs = lab_to_rgb(L, fake_color)\n",
        "    real_imgs = lab_to_rgb(L, real_color)\n",
        "    fig = plt.figure(figsize=(15, 8))\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(3, 5, i + 1)\n",
        "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
        "        ax.imshow(fake_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
        "        ax.imshow(real_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "    if save:\n",
        "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
        "        \n",
        "def log_results(loss_meter_dict):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Training Function and Training the model"
      ],
      "metadata": {
        "id": "y-88Q_sqqcfw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07oYZNml_zz6"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_dl, epochs, display_every=200):\n",
        "    data = next(iter(val_dl)) \n",
        "    for e in range(epochs):\n",
        "        loss_meter_dict = create_loss_meters()  \n",
        "        i = 0                                  \n",
        "        for data in tqdm(train_dl):\n",
        "            model.setup_input(data) \n",
        "            model.optimize()\n",
        "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) \n",
        "            i += 1\n",
        "            if i % display_every == 0:\n",
        "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
        "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
        "                log_results(loss_meter_dict)\n",
        "                visualize(model, data, save=False)\n",
        "\n",
        "model = MainModel()\n",
        "train_model(model, train_dl, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a PreTrained Generator"
      ],
      "metadata": {
        "id": "COka35t8nyAW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5PL-76TkcT6"
      },
      "source": [
        "We will use fastai library's Dynamic U-Net module to easily build our new generator. Modules are loaded previously so there is no need to load them again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWyAdPWgkcT6"
      },
      "outputs": [],
      "source": [
        "def build_res_unet(n_input=1, n_output=2, size=256):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n",
        "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
        "    return net_G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHriuABNkcT6"
      },
      "source": [
        "# Pretraining the generator for colorization task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rut4DS43kcT6"
      },
      "outputs": [],
      "source": [
        "def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n",
        "    for e in range(epochs):\n",
        "        loss_meter = AverageMeter()\n",
        "        for data in tqdm(train_dl):\n",
        "            L, ab = data['L'].to(device), data['ab'].to(device)\n",
        "            preds = net_G(L)\n",
        "            loss = criterion(preds, ab)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            \n",
        "            loss_meter.update(loss.item(), L.size(0))\n",
        "            \n",
        "        print(f\"Epoch {e + 1}/{epochs}\")\n",
        "        print(f\"L1 Loss: {loss_meter.avg:.5f}\")\n",
        "\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "opt = optim.Adam(net_G.parameters(), lr=1e-4)\n",
        "criterion = nn.L1Loss()        \n",
        "pretrain_generator(net_G, train_dl, opt, criterion, 20)\n",
        "torch.save(net_G.state_dict(), \"res18-unet.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model with the new generator"
      ],
      "metadata": {
        "id": "TksYON8SpaNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzXHoU2AkcT7"
      },
      "outputs": [],
      "source": [
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n",
        "model = MainModel(net_G=net_G)\n",
        "train_model(model, train_dl, 20)"
      ]
    }
  ]
}